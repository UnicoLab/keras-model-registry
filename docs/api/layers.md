# ğŸ§© Layers API Reference

Welcome to the KMR Layers documentation! All layers are designed to work exclusively with **Keras 3** and provide specialized implementations for advanced tabular data processing, feature engineering, attention mechanisms, and time series forecasting.

!!! tip "What You'll Find Here"
    Each layer includes detailed documentation with:
    - âœ¨ **Complete parameter descriptions** with types and defaults
    - ğŸ¯ **Usage examples** showing real-world applications
    - âš¡ **Best practices** and performance considerations
    - ğŸ¨ **When to use** guidance for each layer
    - ğŸ”§ **Implementation notes** for developers

!!! success "Modular & Composable"
    These layers can be combined together to create complex neural network architectures tailored to your specific needs.

!!! note "Keras 3 Compatible"
    All layers are built on top of Keras base classes and are fully compatible with Keras 3.

## â±ï¸ Time Series & Forecasting

### ğŸ“ PositionalEmbedding
Fixed sinusoidal positional encoding for transformers and sequence models.

::: kmr.layers.PositionalEmbedding

### ğŸ”§ FixedEmbedding
Non-trainable sinusoidal embeddings for discrete indices (months, days, hours, etc.).

::: kmr.layers.FixedEmbedding

### ğŸ« TokenEmbedding
1D convolution-based embedding layer for time series values.

::: kmr.layers.TokenEmbedding

### â° TemporalEmbedding
Embedding layer for temporal features (month, day, weekday, hour, minute).

::: kmr.layers.TemporalEmbedding

### ğŸ¯ DataEmbeddingWithoutPosition
Combined token and temporal embedding layer for comprehensive feature representation.

::: kmr.layers.DataEmbeddingWithoutPosition

### ğŸƒ MovingAverage
Trend extraction layer using moving average filtering for time series.

::: kmr.layers.MovingAverage

### ğŸ”€ SeriesDecomposition
Trend-seasonal decomposition using moving average.

::: kmr.layers.SeriesDecomposition

### ğŸ“Š DFTSeriesDecomposition
Frequency-based series decomposition using Discrete Fourier Transform.

::: kmr.layers.DFTSeriesDecomposition

### ğŸ”„ ReversibleInstanceNorm
Reversible instance normalization with optional denormalization for time series.

::: kmr.layers.ReversibleInstanceNorm

### ğŸ—ï¸ ReversibleInstanceNormMultivariate
Multivariate version of reversible instance normalization.

::: kmr.layers.ReversibleInstanceNormMultivariate

### ğŸŒŠ MultiScaleSeasonMixing
Bottom-up multi-scale seasonal pattern mixing.

::: kmr.layers.MultiScaleSeasonMixing

### ğŸ“ˆ MultiScaleTrendMixing
Top-down multi-scale trend pattern mixing.

::: kmr.layers.MultiScaleTrendMixing

### ğŸ”€ PastDecomposableMixing
Past decomposable mixing encoder block combining decomposition and multi-scale mixing.

::: kmr.layers.PastDecomposableMixing

## ğŸ¯ Feature Selection & Gating

### ğŸ”€ VariableSelection
Dynamic feature selection using gated residual networks with optional context conditioning.

::: kmr.layers.VariableSelection

### ğŸšª GatedFeatureSelection
Feature selection layer using gating mechanisms for conditional feature routing.

::: kmr.layers.GatedFeatureSelection

### ğŸŒŠ GatedFeatureFusion
Combines and fuses features using gated mechanisms for adaptive feature integration.

::: kmr.layers.GatedFeatureFusion

### ğŸ“ GatedLinearUnit
Gated linear transformation for controlling information flow in neural networks.

::: kmr.layers.GatedLinearUnit

### ğŸ”— GatedResidualNetwork
Gated residual network architecture for feature processing with residual connections.

::: kmr.layers.GatedResidualNetwork

## ğŸ‘ï¸ Attention Mechanisms

### ğŸ¯ TabularAttention
Dual attention mechanism for tabular data with inter-feature and inter-sample attention.

::: kmr.layers.TabularAttention

### ğŸ“Š MultiResolutionTabularAttention
Multi-resolution attention mechanism for capturing features at different scales.

::: kmr.layers.MultiResolutionTabularAttention

### ğŸ” InterpretableMultiHeadAttention
Interpretable multi-head attention layer with explainability features.

::: kmr.layers.InterpretableMultiHeadAttention

### ğŸ§  TransformerBlock
Complete transformer block combining self-attention and feed-forward networks.

::: kmr.layers.TransformerBlock

### ğŸ“Œ ColumnAttention
Attention mechanism focused on inter-column (feature) relationships.

::: kmr.layers.ColumnAttention

### ğŸ“ RowAttention
Attention mechanism focused on inter-row (sample) relationships.

::: kmr.layers.RowAttention

## ğŸ“Š Data Preprocessing & Transformation

### ğŸ”„ DistributionTransformLayer
Transforms data distributions (log, Box-Cox, Yeo-Johnson, etc.) for improved analysis.

::: kmr.layers.DistributionTransformLayer

### ğŸ“ DistributionAwareEncoder
Encodes features while accounting for their underlying distributions.

::: kmr.layers.DistributionAwareEncoder

### ğŸ“ˆ AdvancedNumericalEmbedding
Advanced numerical embedding layer for rich feature representations.

::: kmr.layers.AdvancedNumericalEmbedding

### ğŸ“… DateParsingLayer
Parses and processes date/time features.

::: kmr.layers.DateParsingLayer

### ğŸ• DateEncodingLayer
Encodes dates into learnable embeddings for temporal features.

::: kmr.layers.DateEncodingLayer

### ğŸŒ™ SeasonLayer
Extracts and processes seasonal patterns from temporal data.

::: kmr.layers.SeasonLayer

### ğŸ”€ DifferentialPreprocessingLayer
Applies differential preprocessing transformations to features.

::: kmr.layers.DifferentialPreprocessingLayer

### ğŸ”§ DifferentiableTabularPreprocessor
Differentiable preprocessing layer for tabular data end-to-end training.

::: kmr.layers.DifferentiableTabularPreprocessor

### ğŸ¨ CastToFloat32Layer
Type casting layer for ensuring float32 precision.

::: kmr.layers.CastToFloat32Layer

## ğŸŒ Graph & Ensemble Methods

### ğŸ“Š GraphFeatureAggregation
Aggregates features from graph structures for relational learning.

::: kmr.layers.GraphFeatureAggregation

### ğŸ§¬ AdvancedGraphFeatureLayer
Advanced graph feature processing with multi-hop aggregation.

::: kmr.layers.AdvancedGraphFeatureLayer

### ğŸ‘¥ MultiHeadGraphFeaturePreprocessor
Multi-head preprocessing for graph features with parallel aggregation.

::: kmr.layers.MultiHeadGraphFeaturePreprocessor

### ğŸ“ˆ BoostingBlock
Boosting ensemble block for combining weak learners.

::: kmr.layers.BoostingBlock

### ğŸ¯ BoostingEnsembleLayer
Ensemble layer implementing gradient boosting mechanisms.

::: kmr.layers.BoostingEnsembleLayer

### ğŸ“Š TabularMoELayer
Mixture of Experts layer optimized for tabular data.

::: kmr.layers.TabularMoELayer

### ğŸ—ï¸ BusinessRulesLayer
Layer for integrating domain-specific business rules into model.

::: kmr.layers.BusinessRulesLayer

## ğŸ›¡ï¸ Regularization & Robustness

### ğŸ² StochasticDepth
Stochastic depth regularization for improved generalization.

::: kmr.layers.StochasticDepth

### ğŸ—‘ï¸ FeatureCutout
Feature cutout regularization for dropout-like effects on features.

::: kmr.layers.FeatureCutout

### ğŸ¯ SparseAttentionWeighting
Sparse attention weighting for computational efficiency.

::: kmr.layers.SparseAttentionWeighting

## ğŸ”§ Specialized Processing

### ğŸ¢ SlowNetwork
Slow network layer for temporal smoothing and stability.

::: kmr.layers.SlowNetwork

### âš¡ HyperZZWOperator
Specialized hyperparameter operator for advanced transformations.

::: kmr.layers.HyperZZWOperator

## ğŸš¨ Anomaly Detection

### ğŸ“‰ NumericalAnomalyDetection
Detects anomalies in numerical features using statistical methods.

::: kmr.layers.NumericalAnomalyDetection

### ğŸ“Š CategoricalAnomalyDetectionLayer
Detects anomalies in categorical features.

::: kmr.layers.CategoricalAnomalyDetectionLayer
